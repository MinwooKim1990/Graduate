{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "### Practical 3 (Solutions)\n",
    "\n",
    "The purpose of this computer lab is to illustrate how clustering methods, such as Gaussian mixtures or k-means, can be used for the segmentation of images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task in any image analysis is, clearly, to read the image in.\n",
    "\n",
    "We will need two R packages to help us a bit: One to \"open\" the images, and one to rearrange the data imported from them. Please load the two following packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(OpenImageR)\n",
    "require(arrayhelpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we download, open, and visualize an exemplary image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.file(\"http://www.maths.dur.ac.uk/~dma0je/PG/Mix/cliffs.jpg\", destfile=\"cliffs.jpg\", mode=\"wb\")\n",
    "cliffs0 <- readImage(\"cliffs.jpg\")\n",
    "imageShow(cliffs0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to understand a few things about image files here.  On a basic level we distinguish grey scale and color images.\n",
    "\n",
    "**Grey scale images** will usually either come\n",
    "\n",
    "  * as a matrix (such as 1024 x 1024) of grey scale values between 0 and 1, where 1=white and 0=black \n",
    "  * or as a pseudo-color image which consists of three identical copies of the grey scale image; for instance for the object `cliffs0` we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(cliffs0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, note that all three layers contain the same content; e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(cliffs0[,,1]==cliffs0[,,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the plotting, should be said that `imageShow` has taken out some of the difficulty here. There is a deeper-laying twist: A matrix value [i,j] is defined by running the index `i` *downwards vertically*, then  `j` *rightwards horizontally*. However, an image coordinate is defined by a horizontal coordinate, then a vertical (upwards) coordinate. The function `imageShow` has carried out this transformation in the background. If we hadn't this available, we would need to do this manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cliffs1 <- cliffs0[,,1]\n",
    " rotate <- function(x){t(apply(x, 2, rev))}\n",
    " image(rotate(cliffs1), col=gray.colors(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This may take a while!)\n",
    "\n",
    "For **color images**, the three layers of the array will usually refer to the RGB values.  Let us read in another image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(OpenImageR)\n",
    "download.file(\"http://www.maths.dur.ac.uk/~dma0je/PG/Mix/france.jpg\", destfile=\"france.jpg\", mode=\"wb\")\n",
    "france0 <- readImage(\"france.jpg\")\n",
    "imageShow(france0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply again the `dim` function, and check, similarly as above, how many pixels in the first and second layer are identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(france0)\n",
    "sum(france0[,,1]==france0[,,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to convert a color image to a grey scale image, the three layers can be weighted via 0.21 R + 0.72 G + 0.07 B (Luminosity method). Do this. Save the outcome into an object `france1` and apply `imageShow`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "france1<- 0.21*france0[,,1]+0.72*france0[,,2]+0.07*france0[,,3]\n",
    "imageShow(france1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering and segmentation in (1-D) grey scale feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return, for now, to the analysis of grey scale images, and continue with preparing the image with the cliffs for statistical processing. Firstly, the current 1024 x 1024 image is still quite large to deal with. We resize it via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cliffs <- resizeImage(cliffs1, 256, 256, method = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to transform the matrix into a data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cliffs<- array2df(cliffs)\n",
    "dim(Cliffs)\n",
    "names(Cliffs)\n",
    "head(Cliffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the first column contains the grey scales and the other two columns contain the coordinates. Visualize the grey scale distribution (in `Cliffs$cliffs`) through a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(Cliffs$cliffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are three or four clusters in the data, with the leftmost bar representing the black image frame.\n",
    "\n",
    "To identify the clusters, any clustering method can be used. We begin with k-means. Apply `kmeans` with its default options and three (or four) clusters on `Cliffs$cliffs`, and save the resulting object into `fitcliffs.KM`. Apply the `names` function on the fitted object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Some parts of the notebook downwards from here have been commented out in order to reduce the Validation time of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitcliffs.KM<- kmeans(Cliffs$cliffs, 3, nstart=10)\n",
    "names(fitcliffs.KM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant results (for us) are in the component `$centers`, which gives the three cluster centers, and the component `$cluster`, which tells which center is closest to each data point. Display both of these (non-graphically). For the latter, the `table` function is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitcliffs.KM$centers\n",
    "table(fitcliffs.KM$cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick of cluster-based image segmentation is now, for each pixel,  to *replace the original grey scales by the grey scale corresponding to their respective cluster center*. This can be done very efficiently through the following code. Uncomment it, and make it clear to yourself what it does! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.cliffs.KM <- fitcliffs.KM$centers[fitcliffs.KM$cluster]\n",
    "table(post.cliffs.KM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the long vector of grey scales needs to be transformed back into an image. Being unaware of an existing, automated function for that purpose, I provide one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector2image <- function(image.vector, show=TRUE, width=NULL){\n",
    "  N<-length(image.vector)\n",
    "  D<- sqrt(N)\n",
    "  if (is.null(width)){\n",
    "    if ((D %%1) !=0){\n",
    "        stop(\"This is not a square image so you need to give the image width\")\n",
    "      } else {\n",
    "         width<- D\n",
    "      }\n",
    "  }\n",
    "  \n",
    "  height<- N/width \n",
    "  image.matrix<- matrix(image.vector, nrow=height, ncol=width)\n",
    "  \n",
    "  if (show) {\n",
    "    require(OpenImageR)\n",
    "    imageShow(image.matrix)\n",
    "  }\n",
    "  return(image.matrix)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we reconstruct the `segmented' image via"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM.cliff.image<- vector2image(post.cliffs.KM, show=FALSE)\n",
    "class(KM.cliff.image)\n",
    "dim(KM.cliff.image)\n",
    "imageShow(KM.cliff.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the segmentation is not very good. A first attempt could be to change the type of algorithm used to execute k-means.\n",
    "\n",
    "This can be done through the option `algorithm` in function `kmeans`, for instance to `\"Lloyd\"` or ` \"MacQueeen\"`.  **Try this**! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?kmeans\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger differences in segmentation can be expected when going for an entirely different clustering algorithm. Let us now use EM for Gaussian mixtures as implemented previously.\n",
    "\n",
    "We need tor this the R code as from lecture part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estep <- function(dat, p, mu, sigma){         \n",
    "   n <- length(dat)\n",
    "   K <- length(mu) \n",
    "   W <- matrix(0, n,K)\n",
    "   for (i in 1:n){\n",
    "        W[i,]<- p/sigma*exp(-1/(2*sigma^2)*(dat[i]-mu)^2)/sum( p/sigma*exp(-1/(2*sigma^2)*(dat[i]-mu)^2))\n",
    "      }\n",
    "  return(W)\n",
    "}\n",
    "\n",
    "mstep <- function(dat, W){                    \n",
    "   n <- dim(W)[1]\n",
    "   K <- dim(W)[2]\n",
    "   \n",
    "   p  <- apply(W,2,sum)/n\n",
    "   mu <- apply(W*dat,2,sum)/apply(W,2,sum)\n",
    "  \n",
    "   diff <-matrix(0,n, K)\n",
    "   for (k in 1:K){ diff[,k]<- (dat -mu[k])^2  }\n",
    "   var   <- apply(W*diff,2,sum)/apply(W,2,sum)\n",
    "   sigma <- sqrt(var)\n",
    "\n",
    "  return(list(\"p\"=p, \"mu\"=mu,  \"sigma\"=sigma))\n",
    "} \n",
    "\n",
    "em <- function(dat,K, steps=400){                   \n",
    "  p     <- rep(1/K,K)\n",
    "  mu    <- quantile(dat, probs= (1:K)/K-1/(2*K))  \n",
    "  sigma <- rep(sd(dat), K)\n",
    "  \n",
    "  s <- 1\n",
    "  while (s <=steps){\n",
    "    W   <- estep(dat, p, mu, sigma)\n",
    "    fit <- mstep(dat, W)\n",
    "    p   <- fit$p\n",
    "    mu  <- fit$mu\n",
    "    sigma <-fit$sigma\n",
    "    s   <- s+1\n",
    " }\n",
    "    fit<- list(\"p\"=p, \"mu\"=mu, \"sigma\"=sigma,  \"W\" =W)\n",
    " return(fit)  \n",
    " }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `em` function with three (or four) components on `Cliffs$cliffs`, and save the fit into an object `fitcliffs.EM`. Display the resulting parameter estimates (non-graphically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitcliffs.EM <- em(Cliffs$cliffs, K=3, steps=200)\n",
    "fitcliffs.EM[c(\"p\", \"mu\", \"sigma\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the fitted mixture, we use again the function provided in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mix<- function(dat, p, mu, sigma, breaks=25, dens=TRUE, ngrid=401, ...){\n",
    "  try<-  hist(dat, breaks=breaks,  plot=FALSE)\n",
    "  hist(dat, breaks=breaks, freq=FALSE, ylim=c(0, max(try$density)*1.3), col=\"grey93\" , border=\"grey85\",...)\n",
    "  r <- diff(range(dat))\n",
    "  grid<- seq(min(dat)-0.15*r, max(dat)+0.15*r, length=ngrid)\n",
    "  K<- length(p)\n",
    "  if (length(sigma)==1){\n",
    "    sigma<-rep(sigma, K)\n",
    "  }\n",
    "  grid.mat<- matrix(0, ngrid,K)\n",
    "  for (j in 1:K){\n",
    "    grid.mat[,j]<- p[j]*dnorm(grid, mu[j], sigma[j])\n",
    "  }\n",
    "  for (j in 1:K){\n",
    "    lines(grid, grid.mat[,j], col=j+1, lwd=2)\n",
    "  }\n",
    "  if (dens){\n",
    "    lines(grid, apply(grid.mat,1, sum), col=1,lwd=2)\n",
    "  }   \n",
    "  invisible()  \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function onto the fitted mixture from our cliffs image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.mix(Cliffs$cliffs, fitcliffs.EM$p, fitcliffs.EM$mu, fitcliffs.EM$sigma, dens=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see the fitted three components. The next task, is, again, to replace the original grey scales by the grey scale corresponding to their respective cluster center. For mixtures, this is done by allocating *each observation that component to which it belongs with highest probability*.  This information is contained in the weight matrix `W`. Display the first six rows of that matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(fitcliffs.EM$W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is cumbersome to carry out this allocation step manually, so we devise a function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.em<-function(mu, W){\n",
    "  n<- dim(W)[1]\n",
    "  K<- dim(W)[2]\n",
    "  post.image.class<- rep(0,n)\n",
    "  post.image.tone <- rep(0,n)\n",
    "  for (i in 1:n){\n",
    "    post.image.class[i]<-which.max(W[i,])\n",
    "  }\n",
    "  post.image.tone <- mu[post.image.class]\n",
    "  return(list(\"class\"=post.image.class, \"tone\"=post.image.tone))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, uncomment the following to execute this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.cliffs.EM<- post.em(fitcliffs.EM$mu, fitcliffs.EM$W)$tone\n",
    "table(post.cliffs.EM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is a vector of length 65536 which only contains three different values. Finally, the vector needs to be mapped back to a matrix. You can do this through the function `vector2image` in the same way as we did for k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM.cliff.image<- vector2image(post.cliffs.EM, show=FALSE)\n",
    "dim(EM.cliff.image)\n",
    "imageShow(EM.cliff.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see the \"segmented\" image. You should see that the segmentation has been a partial success, with sky, water, and rocks somewhat identified, but with a considerable proportion of \"contaminating\" pixels throughout the image. We can address this problem through an appropriate *filters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Mode filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of a mode filter is to get rid of little contaminations within segments by replacing such \"contaminated\" pixels with a majority vote of neighboring pixels. A simple implementation of a mode filter is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors<-function(d1,d2, j,k, include.center=TRUE){\n",
    "  neigh<-matrix(NA,0,2)\n",
    "  if (include.center){\n",
    "    neigh<-rbind(neigh, c(j,k))\n",
    "  } \n",
    "      if (j>1){neigh<-rbind(neigh, c(j-1,k))}\n",
    "      if (j<d1){neigh<-rbind(neigh, c(j+1,k))}\n",
    "      if (k>1){neigh<-rbind(neigh, c(j, k-1))}\n",
    "      if (k<d2){neigh<-rbind(neigh, c(j,k+1))}\n",
    "  \n",
    "  return(neigh)   \n",
    "  }\n",
    "\n",
    "mode.filter<-function(image.labels, include.center=TRUE){\n",
    "  # image.labels is a d1 x d2 matrix of class labels\n",
    "   require(pracma)\n",
    "   d<-dim(image.labels)\n",
    "   Modes<-matrix(0,d[1], d[2])\n",
    "   neighbors.jk<-NULL\n",
    "   for (j in 1:d[1]){\n",
    "     for (k in 1:d[2]){\n",
    "      neighbors.jk<-neighbors(d[1],d[2],j,k, include.center)      \n",
    "      neighbor.labels<-NULL\n",
    "      neighbor.labels<- image.labels[neighbors.jk]\n",
    "      Modes[j,k]<-Mode(neighbor.labels)\n",
    "    }\n",
    "  }\n",
    "  return(Modes)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function `mode.filter` onto `KM.cliff.image` and `EM.cliff.image`, and in each case use\n",
    "`imageShow` to visualize the final image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KM.cliff.filter<-mode.filter(KM.cliff.image)\n",
    " imageShow(KM.cliff.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM.cliff.filter <- mode.filter(EM.cliff.image)\n",
    " imageShow(EM.cliff.filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering and Segmentation in (3-D) RGB space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only used grey scales for the clustering. If we would like to do carry out the segmentation on an color image (for instance, the original `france.jpg` image above), we need to carry out the clustering in the 3D RGB space. The procedure is pretty analogous to before; the only real difference being that\n",
    "`vector2image` is now applied layer by layer. **Try this!** (It is suggested to use k-means, as mixture models can take quite long to fit.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "France0<-array2df(france0)\n",
    "dim(France0)\n",
    "head(France0)\n",
    "France<- cbind(France0[France0$d3==1, 1], France0[France0$d3==2, 1], France0[France0$d3==3, 1])\n",
    "head(France)\n",
    "\n",
    "fitfrance.KM<- kmeans(France, 4)\n",
    "fitfrance.KM$centers\n",
    "post.france.KM<- fitfrance.KM$centers[fitfrance.KM$cluster,]\n",
    "head(post.france.KM)\n",
    "KM.france.image<-array(0,dim=dim(france0)) \n",
    "dim(KM.france.image)\n",
    "for (j in 1:3){\n",
    "KM.france.image[,,j]<- vector2image(post.france.KM[,j], width=445)\n",
    "}\n",
    "imageShow(KM.france.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
